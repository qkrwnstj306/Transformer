{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9356024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02b502e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('ChatbotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8d0d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb727511",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1f14415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae77e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a41482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(questions))\n",
    "    f.write('\\n'.join(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2288fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"all.txt\"\n",
    "prefix = \"chatbot\"\n",
    "vocab_size = 16000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "\n",
    "line = \"안녕하세요 만나서 반갑습니다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "\n",
    "\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c5ba9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "START_TOKEN = [2]\n",
    "END_TOKEN = [3]\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "        zeros1 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "        zeros2 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "        sentence1 = START_TOKEN + vocab.encode_as_ids(sentence1) + END_TOKEN\n",
    "        zeros1[:len(sentence1)] = sentence1[:MAX_LENGTH]\n",
    "\n",
    "        sentence2 = START_TOKEN + vocab.encode_as_ids(sentence2) + END_TOKEN\n",
    "        zeros2[:len(sentence2)] = sentence2[:MAX_LENGTH]\n",
    "\n",
    "        tokenized_inputs.append(zeros1)\n",
    "        tokenized_outputs.append(zeros2)\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de04273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_encode, answers_encode = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d16c022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2  5566 14968  3210   111     3     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "[   2 5192  217 5936    7    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions_encode[0])\n",
    "print(answers_encode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cdab8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, questions, answers):\n",
    "        questions = np.array(questions)\n",
    "        answers = np.array(answers)\n",
    "        self.inputs = questions\n",
    "        self.dec_inputs = answers[:,:-1]\n",
    "        self.outputs = answers[:,1:]\n",
    "        self.length = len(questions)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.inputs[idx], self.dec_inputs[idx], self.outputs[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataset = SequenceDataset(questions_encode, answers_encode)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab756a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder_d = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        self.linear = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a0704ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "lr = 1e-4\n",
    "model = TFModel(vocab_size+7, 256, 8, 512, 2, 0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "496c47b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.154: 100%|██████████| 185/185 [00:08<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 1.9366499617293074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.915: 100%|██████████| 185/185 [00:08<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 0.9789027858424831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.856: 100%|██████████| 185/185 [00:08<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 0.9131222286739865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.908: 100%|██████████| 185/185 [00:08<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss: 0.8836445576435811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.878: 100%|██████████| 185/185 [00:08<00:00, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss: 0.8614947344805743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.698: 100%|██████████| 185/185 [00:08<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss: 0.8418577451963682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.880: 100%|██████████| 185/185 [00:08<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss: 0.822788547825169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.849: 100%|██████████| 185/185 [00:08<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss: 0.8037312275654561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.871: 100%|██████████| 185/185 [00:08<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss: 0.7844582222603463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.825: 100%|██████████| 185/185 [00:08<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss: 0.7648574416701858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.787: 100%|██████████| 185/185 [00:08<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss: 0.7447799270217483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.755: 100%|██████████| 185/185 [00:08<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss: 0.7238286198796453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.710: 100%|██████████| 185/185 [00:08<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss: 0.7033576759132179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.658: 100%|██████████| 185/185 [00:08<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss: 0.6821615683065878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.614: 100%|██████████| 185/185 [00:08<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss: 0.6617091823268582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.676: 100%|██████████| 185/185 [00:08<00:00, 21.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss: 0.6398701435810811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.658: 100%|██████████| 185/185 [00:08<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss: 0.6182845244536529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.528: 100%|██████████| 185/185 [00:08<00:00, 21.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss: 0.5960989874762458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.679: 100%|██████████| 185/185 [00:08<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss: 0.5742969409839527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.630: 100%|██████████| 185/185 [00:08<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | loss: 0.5526354403109164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.500: 100%|██████████| 185/185 [00:08<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | loss: 0.5302459716796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.510: 100%|██████████| 185/185 [00:08<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | loss: 0.5084534516205659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.495: 100%|██████████| 185/185 [00:08<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | loss: 0.486576678301837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.502: 100%|██████████| 185/185 [00:08<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | loss: 0.4646118576462204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.451: 100%|██████████| 185/185 [00:08<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | loss: 0.44229521880278716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.371: 100%|██████████| 185/185 [00:08<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | loss: 0.4216374577702703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.423: 100%|██████████| 185/185 [00:08<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | loss: 0.3999787201752534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.387: 100%|██████████| 185/185 [00:08<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | loss: 0.37947412439294764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.438: 100%|██████████| 185/185 [00:08<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | loss: 0.359249548009924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.418: 100%|██████████| 185/185 [00:08<00:00, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | loss: 0.33999487387167443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(dataloader)\n",
    "    for (inputs, dec_inputs, outputs) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "        src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "\n",
    "        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f211e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"chatbot.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbb44579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n",
    "    output = torch.tensor([START_TOKEN]).to(device)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(output).to(device)\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.to(device)], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.DecodeIds(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dec2272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 배고파\n",
      "Output: 뭐라도 드세요 .\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"chatbot.pth\"))\n",
    "result = predict(\"배고파\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1aa344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 머리가 아파,,\n",
      "Output: 잠시 쉬어도 괜찮습니다 .\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"머리가 아파\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b41bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
